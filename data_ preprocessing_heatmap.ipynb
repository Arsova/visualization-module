{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "# data = pd.read_csv('data/data_elog_eindhoven.csv', sep = ';')\n",
    "data = pd.read_csv('data/data_elog_eindhoven_2.csv', sep = ';')\n",
    "# Delete columns\n",
    "to_delete = ['Unnamed: 0', 'index']\n",
    "data.drop(to_delete, axis=1, inplace=True)\n",
    "\n",
    "#Sorth the data\n",
    "data.sort_values(['location', 'UTC_time' ], ascending=[True, True], inplace=True)\n",
    "def calculate_diff(data): \n",
    "    \"\"\"\n",
    "    In this function the consumption difference is calculated per user.\n",
    "    \"\"\"\n",
    "    def diff_func(df): return df.diff()\n",
    "    data['delta_total'] = data.groupby('location')['total'].apply(diff_func)\n",
    "    \n",
    "    return data.reset_index(drop=True)\n",
    "\n",
    "data = calculate_diff(data)\n",
    "\n",
    "#Create new varianbles\n",
    "data['dummy'] = 1\n",
    "data['datetime64'] = pd.to_datetime(data['UTC_time'])\n",
    "data['norm_date'] = data['datetime64'].dt.normalize()\n",
    "data['year'] = data['datetime64'].dt.year\n",
    "data['month'] = data['datetime64'].dt.month\n",
    "data['day'] = data['datetime64'].dt.day\n",
    "data['hour'] = data['datetime64'].dt.hour\n",
    "data = data[data['year'] == 2017] #Only files in 2017\n",
    "data.to_csv('data/data_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Agregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_aggregation(data, aggegation_method = 'sum'):\n",
    "    \"\"\"\n",
    "    This funtion creates the matrices that will be use to generate the heat maps\n",
    "    Params:\n",
    "    data: the elog data set\n",
    "    aggegation_method: how to aggregate the data ['sum', 'mean', 'median']\n",
    "    Return:\n",
    "    hour_consuption: Matrix with the average water consuption per time slot (hour)\n",
    "    \"\"\"\n",
    "    # Here we create the matrices that will be shown at the heat-map\n",
    "    data = data.dropna()\n",
    "    \n",
    "    if aggegation_method == 'median':\n",
    "        hour_consuption = data.groupby(by = ['norm_date', 'hour'])['delta_total'].median()\n",
    "   \n",
    "    elif aggegation_method == 'sum':\n",
    "        hour_consuption = data.groupby(by = ['norm_date', 'hour'])['delta_total'].sum()\n",
    "        \n",
    "    elif aggegation_method == 'mean':\n",
    "        hour_consuption = data.groupby(by = ['norm_date', 'hour'])['delta_total'].mean() \n",
    "        \n",
    "    else:\n",
    "        print('The option {} does not exist, please select [sum, mean, median]'.format(aggegation_method))\n",
    "        sys.exit()\n",
    "        \n",
    "    num_locations = data.groupby(by = ['norm_date', 'hour'] , as_index=False).apply(lambda x: x.location.nunique()) #This must be cheched, all values are 5\n",
    "    # Change formats\n",
    "    def format_change(df):\n",
    "        df = df.unstack()\n",
    "        df.index = df.index.astype(str)\n",
    "        df.columns = df.columns.astype(str)  \n",
    "        df = df.T\n",
    "        df.columns.name = 'date'\n",
    "        return df\n",
    "    \n",
    "    hour_consuption = format_change(hour_consuption)\n",
    "    num_locations = format_change(num_locations)\n",
    "    \n",
    "    assert hour_consuption.shape == num_locations.shape, 'different shapes'\n",
    "\n",
    "    return hour_consuption, num_locations\n",
    "\n",
    "hour_consuption, num_locations = data_aggregation(data, 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a file per location\n",
    "def create_files_HM(data, total = False):\n",
    "    \"\"\"\n",
    "    This function creates a csv file for every customer. This Information is later used to create heat maps\n",
    "    \n",
    "    data: the elog data set\n",
    "    Total: Boolean function. If is true, it will create the total consumption \n",
    "    \n",
    "    Return:\n",
    "    hour_consuption: Matrix with the average water consuption per time slot (hour)\n",
    "    \"\"\"\n",
    "        \n",
    "    unique_location = data['location'].unique()\n",
    "    \n",
    "    for i in unique_location:\n",
    "        temp_data = data[data['location'] == i]\n",
    "        hour_consuption, num_locations = data_aggregation(temp_data, 'sum')\n",
    "        aggregated_day = hour_consuption.sum(axis=0)\n",
    "        aggregated_day = aggregated_day.reset_index()\n",
    "        aggregated_day.columns = ['norm_date', 'total_consuption']\n",
    "        \n",
    "        hour_consuption.to_csv('data/Data_heat_maps/hour_consuption/{}.csv'.format(str(i)),index = False)\n",
    "        num_locations.to_csv('data/Data_heat_maps/num_locations/{}.csv'.format(str(i)), index = False)\n",
    "        aggregated_day.to_csv('data/Data_heat_maps/aggregated_day/{}.csv'.format(str(i)), index = False)\n",
    "    \n",
    "    if total:\n",
    "        aggregated_day_total = pd.DataFrame(data.groupby(by = ['location', 'norm_date'])['delta_total'].sum())\n",
    "        aggregated_day_total.to_csv('data/Data_heat_maps/aggregated_day/aggregated_day_total.csv')\n",
    "        hour_consuption, num_locations = data_aggregation(data, 'median')\n",
    "        hour_consuption.to_csv('data/Data_heat_maps/hour_consuption/hour_consuption_total_median.csv',index = False)\n",
    "        num_locations.to_csv('data/Data_heat_maps/num_locations/num_locations_total_median.csv',index = False)\n",
    "                           \n",
    "create_files_HM(data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To test\n",
    "data_hp = pd.read_csv('data/Data_heat_maps/hour_consuption/1163208.csv')\n",
    "data_aggregated = pd.read_csv('data/Data_heat_maps/aggregated_day/aggregated_day_total_2.csv')\n",
    "data_CC = pd.read_csv('data/Data_heat_maps/Customer Contacts/limited_occ_with_gps_time.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
